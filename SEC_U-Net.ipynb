{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_SEM_block_1(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention_SEM_block_1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ch_1, ch_2, ch_3, ch_4, ch_5):\n",
    "        super(Attention_SEM_block_1, self).__init__()\n",
    "        self.n_channels = ch_1\n",
    "        \n",
    "        self.W_2 = nn.Sequential(\n",
    "            nn.Conv2d(ch_2, ch_1, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.W_3 = nn.Sequential(\n",
    "            nn.Conv2d(ch_3, ch_1, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.W_4 = nn.Sequential(\n",
    "            nn.Conv2d(ch_4, ch_1, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.W_5 = nn.Sequential(\n",
    "            nn.Conv2d(ch_5, ch_1, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(ch_1, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, layer1, layer2, layer3, layer4, layer5):\n",
    "        conv2 = self.W_2(layer2)\n",
    "        conv3 = self.W_3(layer3)\n",
    "        conv4 = self.W_4(layer4)\n",
    "        conv5 = self.W_5(layer5)\n",
    "        w_2 = torch.nn.functional.interpolate(conv2, size = (layer1.shape[2], layer1.shape[3]), mode='bilinear', align_corners=False)\n",
    "        w_3 = torch.nn.functional.interpolate(conv3, size = (layer1.shape[2], layer1.shape[3]), mode='bilinear', align_corners=False)\n",
    "        w_4 = torch.nn.functional.interpolate(conv4, size = (layer1.shape[2], layer1.shape[3]), mode='bilinear', align_corners=False)\n",
    "        w_5 = torch.nn.functional.interpolate(conv5, size = (layer1.shape[2], layer1.shape[3]), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        psi = self.relu(layer1 + w_2 + w_3 + w_4 + w_5)\n",
    "        psi = self.psi(psi)\n",
    "        output = layer1 * psi\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_SEM_block_2(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention_SEM_block_2\n",
    "    \"\"\"\n",
    "    def __init__(self, ch_2, ch_3, ch_4, ch_5):\n",
    "        super(Attention_SEM_block_2, self).__init__()\n",
    "        self.n_channels = ch_2\n",
    "        \n",
    "        self.W_3 = nn.Sequential(\n",
    "            nn.Conv2d(ch_3, ch_2, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.W_4 = nn.Sequential(\n",
    "            nn.Conv2d(ch_4, ch_2, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.W_5 = nn.Sequential(\n",
    "            nn.Conv2d(ch_5, ch_2, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(ch_2, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, layer2, layer3, layer4, layer5):\n",
    "        conv3 = self.W_3(layer3)\n",
    "        conv4 = self.W_4(layer4)\n",
    "        conv5 = self.W_5(layer5)\n",
    "        w_3 = torch.nn.functional.interpolate(conv3, size = (layer2.shape[2], layer2.shape[3]), mode='bilinear', align_corners=False)\n",
    "        w_4 = torch.nn.functional.interpolate(conv4, size = (layer2.shape[2], layer2.shape[3]), mode='bilinear', align_corners=False)\n",
    "        w_5 = torch.nn.functional.interpolate(conv5, size = (layer2.shape[2], layer2.shape[3]), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        psi = self.relu(layer2 + w_3 + w_4 + w_5)\n",
    "        psi = self.psi(psi)\n",
    "        output = layer2 * psi\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_SEM_block_3(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention_SEM_block_3\n",
    "    \"\"\"\n",
    "    def __init__(self, ch_3, ch_4, ch_5):\n",
    "        super(Attention_SEM_block_3, self).__init__()\n",
    "        self.n_channels = ch_3\n",
    "\n",
    "        self.W_4 = nn.Sequential(\n",
    "            nn.Conv2d(ch_4, ch_3, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_3),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.W_5 = nn.Sequential(\n",
    "            nn.Conv2d(ch_5, ch_3, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_3),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(ch_3, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, layer3, layer4, layer5):\n",
    "        conv4 = self.W_4(layer4)\n",
    "        conv5 = self.W_5(layer5)\n",
    "        w_4 = torch.nn.functional.interpolate(conv4, size = (layer3.shape[2], layer3.shape[3]), mode='bilinear', align_corners=False)\n",
    "        w_5 = torch.nn.functional.interpolate(conv5, size = (layer3.shape[2], layer3.shape[3]), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        psi = self.relu(layer3 + w_4 + w_5)\n",
    "        psi = self.psi(psi)\n",
    "        output = layer3 * psi\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_SEM_block_4(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention_SEM_block_4\n",
    "    \"\"\"\n",
    "    def __init__(self, ch_4, ch_5):\n",
    "        super(Attention_SEM_block_4, self).__init__()\n",
    "        self.n_channels = ch_4\n",
    "\n",
    "        self.W_5 = nn.Sequential(\n",
    "            nn.Conv2d(ch_5, ch_4, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_4),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(ch_4, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, layer4, layer5):\n",
    "        conv5 = self.W_5(layer5)\n",
    "        w_5 = torch.nn.functional.interpolate(conv5, size = (layer4.shape[2], layer4.shape[3]), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        psi = self.relu(layer4 + w_5)\n",
    "        psi = self.psi(psi)\n",
    "        output = layer4 * psi\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "\n",
    "class SEC_Unet(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(SEC_Unet, self).__init__()\n",
    "        self.n_channels = in_ch\n",
    "        self.n_classes = out_ch\n",
    "        self.conv1 = DoubleConv(in_ch, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.conv5 = DoubleConv(512, 1024)\n",
    "        \n",
    "        # self.SEM1 = Attention_SEM_block_1(64, 128, 256, 512, 1024)\n",
    "        self.SEM2 = Attention_SEM_block_2(128, 256, 512, 1024)\n",
    "        self.SEM3 = Attention_SEM_block_3(256, 512, 1024)\n",
    "        self.SEM4 = Attention_SEM_block_4(512, 1024)\n",
    "        \n",
    "        self.up6_mask = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.conv6_mask = DoubleConv(1024, 512)\n",
    "        self.up7_mask = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.conv7_mask = DoubleConv(512, 256)\n",
    "        self.up8_mask = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.conv8_mask = DoubleConv(256, 128)\n",
    "        self.up9_mask = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.conv9_mask = DoubleConv(128, 64)\n",
    "        \n",
    "        self.up6_contour = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.conv6_contour = DoubleConv(1024, 512)\n",
    "        self.up7_contour = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.conv7_contour = DoubleConv(512, 256)\n",
    "        self.up8_contour = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.conv8_contour = DoubleConv(256, 128)\n",
    "        self.up9_contour = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.conv9_contour = DoubleConv(128, 64)\n",
    "        \n",
    "        self.conv_mask = nn.Conv2d(64,out_ch, 1)\n",
    "        self.conv_contour = nn.Conv2d(64,out_ch, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        c1=self.conv1(x)\n",
    "        p1=self.pool1(c1)\n",
    "        c2=self.conv2(p1)\n",
    "        p2=self.pool2(c2)\n",
    "        c3=self.conv3(p2)\n",
    "        p3=self.pool3(c3)\n",
    "        c4=self.conv4(p3)\n",
    "        p4=self.pool4(c4)\n",
    "        c5=self.conv5(p4)\n",
    "        \n",
    "        # sem1 = self.SEM1(c1, c2, c3, c4, c5)\n",
    "        sem2 = self.SEM2(c2, c3, c4, c5)\n",
    "        sem3 = self.SEM3(c3, c4, c5)\n",
    "        sem4 = self.SEM4(c4, c5)\n",
    "        \n",
    "        up_6_mask = self.up6_mask(c5)\n",
    "        merge6_mask = torch.cat([up_6_mask, sem4], dim=1)\n",
    "        c6_mask=self.conv6_mask(merge6_mask)\n",
    "        up_7_mask=self.up7_mask(c6_mask)\n",
    "        merge7_mask = torch.cat([up_7_mask, sem3], dim=1)\n",
    "        c7_mask=self.conv7_mask(merge7_mask)\n",
    "        up_8_mask=self.up8_mask(c7_mask)\n",
    "        merge8_mask = torch.cat([up_8_mask, sem2], dim=1)\n",
    "        c8_mask=self.conv8_mask(merge8_mask)\n",
    "        up_9_mask=self.up9_mask(c8_mask)\n",
    "        merge9_mask=torch.cat([up_9_mask, c1],dim=1)\n",
    "        c9_mask=self.conv9_mask(merge9_mask)\n",
    "        \n",
    "        mask=self.conv_mask(c9_mask)\n",
    "        \n",
    "        up_6_contour = self.up6_contour(c5)\n",
    "        merge6_contour = torch.cat([up_6_contour, c4], dim=1)\n",
    "        c6_contour=self.conv6_contour(merge6_contour)\n",
    "        up_7_contour=self.up7_contour(c6_contour)\n",
    "        merge7_contour = torch.cat([up_7_contour, c3], dim=1)\n",
    "        c7_contour=self.conv7_contour(merge7_contour)\n",
    "        up_8_contour=self.up8_contour(c7_contour)\n",
    "        merge8_contour = torch.cat([up_8_contour, c2], dim=1)\n",
    "        c8_contour=self.conv8_contour(merge8_contour)\n",
    "        up_9_contour=self.up9_contour(c8_contour)\n",
    "        merge9_contour=torch.cat([up_9_contour, c1],dim=1)\n",
    "        c9_contour=self.conv9_contour(merge9_contour)\n",
    "        \n",
    "        contour=self.conv_contour(c9_contour)\n",
    "        \n",
    "        return mask, contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(root):\n",
    "    imgs=[]\n",
    "    for filename in os.listdir(root):\n",
    "        tag = filename.split('.')[0][-1]\n",
    "        if tag != 'r' and tag != 'k':            \n",
    "            img = os.path.join(root, filename)\n",
    "            mask = os.path.join(root, filename.split('.')[0] + '_mask.png')\n",
    "            contour = os.path.join(root, filename.split('.')[0] + '_contour.png')\n",
    "            imgs.append((img,mask, contour))\n",
    "    return imgs\n",
    "\n",
    "\n",
    "class BacteriaDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        imgs = make_dataset(root)\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x_path, y1_path,y2_path = self.imgs[index]\n",
    "\n",
    "        img_x = Image.open(x_path)\n",
    "        img_y1 = Image.open(y1_path)\n",
    "        img_y1 = img_y1.convert('L')\n",
    "        img_y2 = Image.open(y2_path)\n",
    "        img_y2 = img_y2.convert('L')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_x = self.transform(img_x)\n",
    "        if self.target_transform is not None:\n",
    "            img_y2 = self.target_transform(img_y2)\n",
    "            img_y1 = self.target_transform(img_y1)\n",
    "            \n",
    "        return img_x, img_y1, img_y2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "y_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataload, w_contour=1.0, w_mask=0.8, num_epochs=20):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        dt_size = len(dataload.dataset)\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        \n",
    "        for x, y_mask, y_contour in dataload:\n",
    "            step += 1\n",
    "            inputs = x.to(device)\n",
    "            labels_contour = y_contour.to(device)\n",
    "            labels_mask = y_mask.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward\n",
    "            mask_pred, contour_pred = model(inputs)\n",
    "            loss_mask = w_mask * criterion(mask_pred, labels_mask)\n",
    "            loss_contour = w_contour * criterion(contour_pred, labels_contour)\n",
    "\n",
    "            loss = (loss_mask + loss_contour)/(w_contour + w_mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            print(\"%d/%d,train_loss:%0.3f\" % (step, (dt_size - 1) // dataload.batch_size + 1, loss.item()))\n",
    "        print(\"epoch %d loss:%0.3f\" % (epoch, epoch_loss/step))\n",
    "    torch.save(model.state_dict(), 'weights_%d.pth' % epoch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SEC_Unet(3, 1).to(device)\n",
    "batch_size = 5\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "bacteria_dataset = BacteriaDataset(\"./dataset/train\",transform=x_transforms,target_transform=y_transforms)\n",
    "dataloaders = DataLoader(bacteria_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "train_model(model, criterion, optimizer, dataloaders, num_epochs=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "bacteria_dataset_test = BacteriaDataset(\"dataset/test\", transform=x_transforms,target_transform=y_transforms)\n",
    "dataloaders_test = DataLoader(bacteria_dataset_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score():\n",
    "    def __init__(self, y_pred, y_true, size = 512, threshold = 0.5):\n",
    "        self.TN = 0\n",
    "        self.FN = 0\n",
    "        self.FP = 0\n",
    "        self.TP = 0\n",
    "        self.y_pred = y_pred > threshold\n",
    "        self.y_true = y_true\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        for i in range(0, size):\n",
    "            for j in range(0, size):\n",
    "                if self.y_pred[i,j] == 1:\n",
    "                    if self.y_pred[i,j] == self.y_true[i][j]:\n",
    "                        self.TP = self.TP + 1\n",
    "                    else:\n",
    "                        self.FP = self.FP + 1\n",
    "                else:\n",
    "                    if self.y_pred[i,j] == self.y_true[i][j]:\n",
    "                        self.TN = self.TN + 1\n",
    "                    else:\n",
    "                        self.FN = self.FN + 1        \n",
    " \n",
    "    def get_Se(self):\n",
    "        return (self.TP)/(self.TP + self.FN)\n",
    "    \n",
    "    def get_Sp(self):\n",
    "        return (self.TN)/(self.TN + self.FP)\n",
    "    \n",
    "    def get_Pr(self):\n",
    "        return (self.TP)/(self.TP + self.FP)\n",
    "    \n",
    "    def F1(self):\n",
    "        Pr = self.get_Pr()\n",
    "        Se = self.get_Se()\n",
    "        return (2*Pr*Se)/(Pr + Se)\n",
    "    \n",
    "    def G(self):\n",
    "        Sp = self.get_Sp()\n",
    "        Se = self.get_Se()\n",
    "        return math.sqrt(Se*Sp)\n",
    "    \n",
    "    def IoU(self):\n",
    "        Pr = self.get_Pr()\n",
    "        Se = self.get_Se()\n",
    "        return (Pr*Se) /(Pr + Se - Pr*Se)\n",
    "    \n",
    "    def DSC(self):\n",
    "        return (2* self.TP)/(2* self.TP + self.FP + self.FN) \n",
    "    \n",
    "    def PA(self):\n",
    "        return (self.TP + self.TN)/(self.TP + self.FP + self.FN + self.TN)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = []\n",
    "Pre = []\n",
    "Se = []\n",
    "PA = []\n",
    "Sp = []\n",
    "with torch.no_grad():\n",
    "    for x, target1, target2 in dataloaders_test:\n",
    "        y = model(x)\n",
    "        y_pred = torch.squeeze(y[0] - 0.3*y[1]).numpy()\n",
    "        y_true = torch.squeeze(target1).numpy()\n",
    "        y_score = Score(y_pred, y_true, size = 512)\n",
    "        # print((y_score.F1(), y_score.get_Se(), y_score.get_Pr()))\n",
    "        F1 = np.append(F1, y_score.F1())\n",
    "        Pre = np.append(Pre, y_score.get_Pr())\n",
    "        Se = np.append(Se, y_score.get_Se())\n",
    "        PA = np.append(PA, y_score.PA())\n",
    "        Sp = np.append(Sp, y_score.get_Sp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_mean = np.mean(F1)\n",
    "F1_std = np.std(F1,ddof=1)\n",
    "print(F1_mean)\n",
    "print(F1_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
